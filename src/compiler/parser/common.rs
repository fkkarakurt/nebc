//! # Parser Core Utilities
//!
//! This module defines the central [`Parser`] structure and its foundational methods
//! used for consuming tokens generated by the lexer and building the Abstract Syntax Tree (AST).
//!
//! The parser employs a basic recursive descent approach, relying on lookahead (`peek`)
//! and advancement (`advance`) to process the token stream.

use super::statement_parser::StatementParser;
use crate::ast::nodes::Program;
use crate::compiler::error::CompileError;
use crate::compiler::lexer::Token;

/// The main parser structure for the Nebulang compiler.
///
/// It holds the token stream and tracks the current position within the stream.
pub struct Parser {
    /// The sequence of tokens produced by the lexer. Each entry includes:
    /// 1. The [`Token`] type.
    /// 2. Start line index.
    /// 3. End line index.
    /// 4. The raw string value (lexeme).
    pub tokens: Vec<(Token, usize, usize, String)>,
    /// The index of the next token to be consumed.
    pub position: usize,
}

impl Parser {
    /// Creates a new parser instance from a vector of tokens.
    ///
    /// # Arguments
    ///
    /// * `tokens` - The token stream received from the lexer.
    pub fn new(tokens: Vec<(Token, usize, usize, String)>) -> Self {
        Self {
            tokens,
            position: 0,
        }
    }

    /// The main entry point for parsing, responsible for building the root [`Program`] AST node.
    ///
    /// It repeatedly attempts to parse statements until the end of the token stream is reached.
    ///
    /// # Returns
    ///
    /// A `Result` containing the fully constructed [`Program`] AST or a [`CompileError`].
    pub fn parse_program(&mut self) -> Result<Program, CompileError> {
        let mut statements = Vec::new();

        while !self.is_at_end() {
            let _current_pos = self.position; // Retained for potential future error reporting
            match StatementParser::parse_statements(self)? {
                Some(mut parsed_statements) => {
                    statements.append(&mut parsed_statements);
                }
                None => {
                    // If no statement was parsed (e.g., encountering a blank line or comment placeholder), skip it.
                    self.advance();
                }
            }
        }

        Ok(Program { statements })
    }

    /// Provides a lookahead mechanism to inspect the current token without consuming it.
    ///
    /// Returns a placeholder token tuple if the parser is past the end of the stream (EOF).
    ///
    /// # Returns
    ///
    /// A reference to the current token tuple.
    pub fn peek(&self) -> &(Token, usize, usize, String) {
        if self.position < self.tokens.len() {
            &self.tokens[self.position]
        } else {
            // Static EOF placeholder
            static EOF: (Token, usize, usize, String) = (Token::Newline, 0, 0, String::new());
            &EOF
        }
    }

    /// Consumes the current token and advances the parser to the next position.
    pub fn advance(&mut self) {
        if self.position < self.tokens.len() {
            self.position += 1;
        }
    }

    /// Checks if the current token matches the expected token type without consuming it.
    ///
    /// # Arguments
    ///
    /// * `token` - The expected [`Token`] type.
    ///
    /// # Returns
    ///
    /// `true` if the current token matches and is not EOF, `false` otherwise.
    pub fn check(&self, token: Token) -> bool {
        !self.is_at_end() && self.peek().0 == token
    }

    /// Consumes the current token, but only if it matches the expected type.
    ///
    /// If the token does not match, a parsing error is returned, stopping compilation.
    ///
    /// # Arguments
    ///
    /// * `expected` - The [`Token`] type that must be present next.
    ///
    /// # Returns
    ///
    /// An `Ok(())` on success, or a [`CompileError`] on failure.
    pub fn expect(&mut self, expected: Token) -> Result<(), CompileError> {
        if self.check(expected.clone()) {
            self.advance();
            Ok(())
        } else {
            let (found, start, _, _) = self.peek();
            let message = format!("Expected {:?}, found {:?}", expected, found);
            // In a real compiler, 'start' would be used to point to the error location.
            Err(CompileError::parser(message))
        }
    }

    /// Checks if the parser has consumed all available tokens.
    ///
    /// # Returns
    ///
    /// `true` if the current position is past the end of the token vector.
    pub fn is_at_end(&self) -> bool {
        self.position >= self.tokens.len()
    }

    /// Retrieves the string value of the current token, assuming it is an `Identifier`.
    ///
    /// **Warning**: This method performs no type check and should be used cautiously after `check` or `expect`.
    ///
    /// # Returns
    ///
    /// The string name of the identifier, or an empty string if the current token is not an `Identifier`.
    pub fn get_identifier(&mut self) -> String {
        if let Token::Identifier(name) = &self.peek().0 {
            name.clone()
        } else {
            String::new()
        }
    }
}
